---
title: "GPU 那些事儿"
date: 2020-09-01T11:33:47+08:00
draft: false
tags: 
categories: 
featured_image: 
description: 
---
## 概念解释
#### MapReduce 
为离线批处理服务的模型，分成 Map 任务分发和 Reduce 结果收集两个阶段，能以相同方式处理不同数据来源的大数据作业。

根据数据来源的不同和作业特点分为

- 批计算
- 流计算, 处理连续的大规模数据流，将无界的数据流划分成固定大小的有界批处理子集
- 内存计算, 中间数据需要大量的迭代处理 ，把Map任务中的中间数据保存到内存中。
- 图计算，有依赖关系的多个子任务的 MapReduce 迭代计算形式。
- 交互计算, 对计算延迟敏感，或是包含多种计算模式的复杂作业。

#### Spark 和 Flink
大数据处理框架，提供基于 MapReduce 模式的批处理、流计算、内存计算和图计算等多种计算模式 ，来处理不同输入形式的大数据作业。

##### Flink 
虽然没有使用 Flink, 但是需要了解 Flink 能做什么。

- 事件驱动型应用
- 数据分析应用
- 数据管道应用

详细查看 [Flink 应用场景][flink-usecase]

##### Spark

#### BSP
并行计算模型中， 大同步并行模型，该模型可表示由多个超级步组成的计算过程。在每个超级步中各处理器执行局部计算，再完成点点数据同行，最后全局同步检查来确定所有处理器是否完成运算。


#### DOT 模型
在BSP基础上，研究者扩展可用于大数据计算计算模型。

采用矩阵形式化描述大数据处理的计算和通信行为. 将计算过程分为三个层次： 数据层、操作层、转换层。

#### DOTA 模型 
中科院徐志伟团队提出, 在原来的 DOT 模型基础上，增加聚合层（A-Layer）回合处理转移层的中间数据并且完成最终结果。

#### p-DOT 模型
该模型沿用 BSP 的思路把大数据计算任务视为 p 阶段的 DOT 模型。在多次迭代的计算阶段内，p-DOT 模型由数据层、计算层、通信层构成。

## 并行计算
来自《并行计算》  

## K8S & GPU
**在一个 1 GPU 上跑多个 Job?**, 按照文章的思路是可以实现的。

社区讨论： 

- https://github.com/NVIDIA/k8s-device-plugin/issues/169
- https://github.com/kubernetes/kubernetes/issues/52757


[TKE 上实现 GPU Share](https://github.com/tkestack/gpu-manager) 从测试数据以及 GIGAStack 产品，这种方案在正式环境上run起来的

- [论文笔记《GaiaGPU：Sharing GPUs in Container Clouds》](https://pokerfacesad.github.io/2020/02/07/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%8AGaiaGPU%20Sharing%20GPUs%20in%20Container%20Clouds%E3%80%8B/)
- [GaiaStack上的GPU虚拟化技术](https://cloud.tencent.com/developer/article/1389547)
- [GaiaGPU: Sharing GPUs in Container Clouds 论文地址](https://ieeexplore.ieee.org/abstract/document/8672318)
- [Kubernetes 多卡GPU使用和分析](https://cloud.tencent.com/developer/article/1496699)

[GPU Sharing Scheduler Extender in Kubernetes](https://github.com/AliyunContainerService/gpushare-scheduler-extender) 阿里云上实现 GPU Share

- [GPU Sharing Scheduler Extender Now Supports Fine-Grained Kubernetes Clusters ](https://www.alibabacloud.com/blog/gpu-sharing-scheduler-extender-now-supports-fine-grained-kubernetes-clusters_594926) 
- [GPU Sharing in Kubernetes](https://github.com/AliyunContainerService/gpushare-scheduler-extender/blob/master/docs/designs/designs.md) 阿里云共享 GPU 的设计。

[KubeShare - Share GPU between Pods in Kubernetes ](https://github.com/NTHU-LSALAB/KubeShare) 学校试验， 不确定在生产环境稳定运行。


### GPU 虚拟化技术
想解决 GPU 资源合理分配问题， 先将设备虚拟化。

### NVIDIA GPU OPERATOR
在 [Prometheus Proactise之设备插件 device-plugin](http://hyvi.github.io/docs/architecture/2020-11-06-prometheus-practise/#%E8%AE%BE%E5%A4%87%E6%8F%92%E4%BB%B6--device-plugin) 提到 Kubernetes 下如何支持新的硬件。

Configuring and Managing nodes with these hardware resources require configuration of multiple software components such as drivers, container runtimes or other libraries which are difficult and prone to errors. 

The Nvidia GPU Operator  uses the operator framework within kubernetes to automate the management of all NVIDIA software components needed to provison GPU. These components include the NVIDIA drivers (to enable CUDA), Kubernetes device plugin for GPUs, the NVIDIA Container Toolkit, automatic node labelling using GFD, DCGM based monitoring and others. 

## 参考 

[NVIDIA GPU OPERATOR](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/overview.html#getting-started) 

[深入了解 GPU 硬件架构及运行机制][gpu-arch] 非常全面的介绍

[并行计算](https://pop0726.github.io/bxjs/text/catalog/content1.htm)  在线课程，必读

[论文：面向大数据复杂应用的 GPU 协同计算模型]()

[Flink 应用场景][flink-usecase]

[gpu-arch]: https://www.cnblogs.com/timlly/p/11471507.html#324-nvidia-kepler%E6%9E%B6%E6%9E%84

[flink-usecase]: https://flink.apache.org/zh/usecases.html
<br>

<center>  ·End·  </center>
